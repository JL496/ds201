{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Lab is due on  10/23 at 11:59 pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is about participants who completed the personal information form and a divorce predictors scale. The data is a modified version of the publicly available data at https://archive.ics.uci.edu/ml/datasets/Divorce+Predictors+data+set by injecting noise so you will not replicate the results on the UCI website. There are 170 participants and 54 attributes (or predictor variables) that are all real-valued. The dataset is named as divorce.csv. The last column of the CSV file is labeled y (1 means “divorce,” 0 means “no divorce”). Each column is for one feature (predictor variable), and each row is a sample (participant). A detailed explanation for each feature (predictor variable) is at the website link above.\n",
    "We will be using Sklearn very often from now on. We will have to learn this about this package. Please read all about it here https://scikit-learn.org/stable/index.html \n",
    "\n",
    "Adding/injecting noise in the data: https://stackoverflow.com/questions/46093073/adding-gaussian-noise-to-a-dataset-of-floating-points-and-save-it-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 [20]\n",
    "Please load the divorce data that is in CSV form. Make sure to add Header = None when uploading it. Separate the last column as y and all other columns as x. Use all the data x and y to train a logistic regression model using the LogisticRegression function from the Sklearn library here\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "Once you fit the model (no tuning required), make predictions on the whole data set x, report the accuracy score, and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.560903</td>\n",
       "      <td>3.681587</td>\n",
       "      <td>3.450467</td>\n",
       "      <td>3.211998</td>\n",
       "      <td>-1.203045</td>\n",
       "      <td>0.597706</td>\n",
       "      <td>-0.970093</td>\n",
       "      <td>-0.750970</td>\n",
       "      <td>-0.511495</td>\n",
       "      <td>-0.133660</td>\n",
       "      <td>...</td>\n",
       "      <td>2.077401</td>\n",
       "      <td>1.184182</td>\n",
       "      <td>3.955069</td>\n",
       "      <td>2.608046</td>\n",
       "      <td>2.303629</td>\n",
       "      <td>1.721660</td>\n",
       "      <td>3.275018</td>\n",
       "      <td>1.761019</td>\n",
       "      <td>1.215237</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.153272</td>\n",
       "      <td>5.173858</td>\n",
       "      <td>4.100690</td>\n",
       "      <td>2.580173</td>\n",
       "      <td>3.305788</td>\n",
       "      <td>-1.505512</td>\n",
       "      <td>-0.029398</td>\n",
       "      <td>5.702657</td>\n",
       "      <td>2.230281</td>\n",
       "      <td>4.975496</td>\n",
       "      <td>...</td>\n",
       "      <td>3.467076</td>\n",
       "      <td>2.451984</td>\n",
       "      <td>3.504294</td>\n",
       "      <td>5.324240</td>\n",
       "      <td>4.480607</td>\n",
       "      <td>5.375248</td>\n",
       "      <td>2.270379</td>\n",
       "      <td>2.167944</td>\n",
       "      <td>2.191214</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.226241</td>\n",
       "      <td>1.575322</td>\n",
       "      <td>2.389117</td>\n",
       "      <td>2.725405</td>\n",
       "      <td>-0.304562</td>\n",
       "      <td>2.832803</td>\n",
       "      <td>1.787779</td>\n",
       "      <td>0.565755</td>\n",
       "      <td>1.328212</td>\n",
       "      <td>2.335353</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200917</td>\n",
       "      <td>1.241794</td>\n",
       "      <td>2.207492</td>\n",
       "      <td>1.228034</td>\n",
       "      <td>0.870052</td>\n",
       "      <td>1.685040</td>\n",
       "      <td>2.341985</td>\n",
       "      <td>-0.444320</td>\n",
       "      <td>2.527452</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.553458</td>\n",
       "      <td>2.859042</td>\n",
       "      <td>2.928414</td>\n",
       "      <td>1.833241</td>\n",
       "      <td>1.271119</td>\n",
       "      <td>4.165213</td>\n",
       "      <td>2.078597</td>\n",
       "      <td>4.506175</td>\n",
       "      <td>2.521628</td>\n",
       "      <td>2.747315</td>\n",
       "      <td>...</td>\n",
       "      <td>3.196291</td>\n",
       "      <td>2.204824</td>\n",
       "      <td>3.664982</td>\n",
       "      <td>3.689508</td>\n",
       "      <td>2.577677</td>\n",
       "      <td>3.171884</td>\n",
       "      <td>2.164660</td>\n",
       "      <td>1.813024</td>\n",
       "      <td>1.376033</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.506547</td>\n",
       "      <td>1.419223</td>\n",
       "      <td>1.716153</td>\n",
       "      <td>1.319274</td>\n",
       "      <td>2.853840</td>\n",
       "      <td>0.047412</td>\n",
       "      <td>-0.016515</td>\n",
       "      <td>0.620795</td>\n",
       "      <td>1.202992</td>\n",
       "      <td>0.078347</td>\n",
       "      <td>...</td>\n",
       "      <td>1.806657</td>\n",
       "      <td>2.085539</td>\n",
       "      <td>2.012551</td>\n",
       "      <td>1.899477</td>\n",
       "      <td>1.510134</td>\n",
       "      <td>1.373350</td>\n",
       "      <td>2.551119</td>\n",
       "      <td>0.846321</td>\n",
       "      <td>-0.066858</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  1.560903  3.681587  3.450467  3.211998 -1.203045  0.597706 -0.970093   \n",
       "1  4.153272  5.173858  4.100690  2.580173  3.305788 -1.505512 -0.029398   \n",
       "2  2.226241  1.575322  2.389117  2.725405 -0.304562  2.832803  1.787779   \n",
       "3  3.553458  2.859042  2.928414  1.833241  1.271119  4.165213  2.078597   \n",
       "4  0.506547  1.419223  1.716153  1.319274  2.853840  0.047412 -0.016515   \n",
       "\n",
       "         7         8         9   ...        45        46        47        48  \\\n",
       "0 -0.750970 -0.511495 -0.133660  ...  2.077401  1.184182  3.955069  2.608046   \n",
       "1  5.702657  2.230281  4.975496  ...  3.467076  2.451984  3.504294  5.324240   \n",
       "2  0.565755  1.328212  2.335353  ...  1.200917  1.241794  2.207492  1.228034   \n",
       "3  4.506175  2.521628  2.747315  ...  3.196291  2.204824  3.664982  3.689508   \n",
       "4  0.620795  1.202992  0.078347  ...  1.806657  2.085539  2.012551  1.899477   \n",
       "\n",
       "         49        50        51        52        53   54  \n",
       "0  2.303629  1.721660  3.275018  1.761019  1.215237  1.0  \n",
       "1  4.480607  5.375248  2.270379  2.167944  2.191214  1.0  \n",
       "2  0.870052  1.685040  2.341985 -0.444320  2.527452  1.0  \n",
       "3  2.577677  3.171884  2.164660  1.813024  1.376033  1.0  \n",
       "4  1.510134  1.373350  2.551119  0.846321 -0.066858  1.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div = pd.read_csv('divorce.csv', header = None)\n",
    "y = div[54]\n",
    "cols = list(div.columns)\n",
    "x = div[cols[0:53]]\n",
    "div.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'return_X_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1abc54b38709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_X_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#lrmodel = LogisticRegression(solver = 'liblinear')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'return_X_y' is not defined"
     ]
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y)\n",
    "clf = LogisticRegression(random_state=0).fit(X,y)\n",
    "clf.predict(X[:2, :])\n",
    "clf.predict_proba(X[:2, :])\n",
    "#lrmodel = LogisticRegression(solver = 'liblinear')\n",
    "#lrmodel.fit(x,y)\n",
    "#ypredlr = lrmodel.predict(x)\n",
    "#print(\"Accuracy:\",metrics.accuracy_score(y, ypredlr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2  [30]\n",
    "Out of 54 features, choose only 40 most important variables. Divide the data x, and y with 70%, 30% rule. Train the logistic regression model. You decide how you want to pick 40 important features. Looking at statmodels logistic regression summary or Sklearn logistic regression summary is one way. Sklearn has a feature selection function  https://scikit-learn.org/stable/modules/feature_selection.html which helps you to select important features. Report the accuracy and the confusion matrix for the training and testing data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
